#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_evaluation_suite.py (Corrected & Robust Version)

æ­¤è„šæœ¬åŸºäºå››çº§éªŒè¯é€»è¾‘ï¼Œå®ç°äº†å¤§è§„æ¨¡ã€å…¨è‡ªåŠ¨çš„è§†é¢‘ç”Ÿæˆå¥—ä»¶ã€‚
å®ƒä¼šéå†ä¸€ç»„é¢„å®šä¹‰çš„11ä¸ªPromptså’Œ3ä¸ªéšæœºç§å­ï¼Œä¸ºæ¯ä¸ªç»„åˆç”Ÿæˆå››ä¸ª
è¯„ä¼°çº§åˆ«çš„è§†é¢‘ï¼Œç”¨äºå…¨é¢çš„æ¨¡å‹æ•ˆæœå¯¹æ¯”ã€‚

The 4 Levels of Evaluation:
1.  **Level 0: Absolute Baseline**
    -   ä½¿ç”¨çº¯å‡€çš„ Wan2.1 åŸºç¡€æ¨¡å‹ã€‚
2.  **Level 1: Style Baseline**
    -   åœ¨åŸºç¡€æ¨¡å‹ä¸Šåº”ç”¨å¤–éƒ¨çš„æ°´å¢¨é£æ ¼ LoRAã€‚
3.  **Level 2: Jointly Trained Style**
    -   ä½¿ç”¨åœ¨æ—¶åºè®­ç»ƒä¸­è¢«å¾®è°ƒè¿‡çš„ DiT æ¨¡å‹ï¼ˆé£æ ¼å·²å†…åŒ–ï¼‰ã€‚
4.  **Level 3: Fully Enhanced Model**
    -   ä½¿ç”¨å¾®è°ƒåçš„ DiT æ¨¡å‹ï¼Œå¹¶åŠ è½½æ—¶åºæ¨¡å—ï¼ˆTemporal Module + Flow Predictorï¼‰ã€‚
"""
import sys
import torch
from pathlib import Path
from tqdm import tqdm
import traceback

# ============================================================================
# 1. è®¾ç½®è·¯å¾„ä¸å¯¼å…¥ä¾èµ–
# ============================================================================
try:
    import diffsynth
except ImportError:
    repo_root = Path(__file__).resolve().parent
    sys.path.append(str(repo_root))
    print(f"Added {repo_root} to sys.path")

from diffsynth.pipelines.wan_video_new import WanVideoPipeline
from diffsynth.data.video import save_video
from diffsynth.modules.temporal_module import TemporalModule
from diffsynth.modules.latent_flow_predictor import LatentFlowPredictor
from diffsynth.utils import ModelConfig

# ============================================================================
# 2. è¯„ä¼°æ•°æ®ä¸é…ç½®
# ============================================================================

# --- å®Œæ•´çš„11ä¸ªè¯„ä¼°ç”¨Promptsåˆ—è¡¨ ---
EVALUATION_PROMPTS = [
    {
        "id": "prompt_01_detailed_calligraphy",
        "english": "In a high-contrast black and white ink wash style, a woman in hanfu paints on an ancient bridge. The camera slowly pans horizontally, transitioning from a close-up to a half-body view. She makes continuous long brush strokes, with the wet ink naturally flowing and diffusing. Requires frame-to-frame coherence and strong negative space. 8 frames.",
        "num_frames": 17 # 8å¸§è§†é¢‘é€šå¸¸ä½¿ç”¨17å¸§è¾“å…¥ä»¥è·å¾—æ›´å¥½æ•ˆæœ
    },
    {
        "id": "prompt_02_slow_calligraphy",
        "english": "Black-and-white ink-wash style, a woman in hanfu slowly painting on an ancient bridge, long continuous brush strokes with ink flow and natural bleeding, slow lateral camera pan, 8 frames. Require frame-to-frame continuity, continuous strokes, no flicker or broken strokes, strong negative space.",
        "num_frames": 17
    },
    {
        "id": "prompt_03_fast_action",
        "english": "Ink wash style, a young warrior swiftly swings a sword, brush strokes and ink droplets are rapidly flung out, emphasizing the ink trajectory during high-speed motion, 8 frames. Forcing no breaks or jitter.",
        "num_frames": 17
    },
    {
        "id": "prompt_04_negative_space",
        "english": "On a blank rice paper with significant negative space, a brush tip slowly drags across. The negative space subtly changes with the stroke, showing a smooth temporal variation of the white area, 8 frames. Low jitter required.",
        "num_frames": 17
    },
    {
        "id": "prompt_05_wet_to_dry",
        "english": "A single long brush stroke. Wet ink begins to bleed outward and then gradually dries, emphasizing the continuity of the bleeding and edge deformation, 8 frames. Frame-to-frame coherence is required.",
        "num_frames": 17
    },
    {
        "id": "prompt_06_occlusion_recovery",
        "english": "In the frame, a hand briefly occludes the brush tip and then moves away. The ink stroke extends continuously at the point of occlusion, testing the quality of recovery from occlusion-induced breaks, 8 frames.",
        "num_frames": 17
    },
    {
        "id": "prompt_07_edge_consistency",
        "english": "Complex tree branch line art, outlined with a pen-style ink wash. Emphasizes the preservation and coherence of the edge contour, 8 frames. High edge consistency (no broken edges) required.",
        "num_frames": 17
    },
    {
        "id": "prompt_08_multi_brush",
        "english": "Two brushes alternately draw interwoven strokes on paper, with the ink overlapping and flowing together. Tests the coherence at the intersections of the strokes, 8 frames.",
        "num_frames": 17
    },
    {
        "id": "prompt_09_long_zoom",
        "english": "A slow-panning long shot. The view gradually zooms out from a close-up of brush stroke details to a full view of the rice paper, observing the coherence of strokes during the zoom, 16 frames, low speed.",
        "num_frames": 17 # 16å¸§è§†é¢‘åŒæ ·å»ºè®®ä½¿ç”¨17å¸§è¾“å…¥
    },
    {
        "id": "prompt_10_particle_merge",
        "english": "Ink droplets splash on paper, forming petal shapes. Then, a gentle wind causes the ink petals to move slowly, 8 frames. Tests the merging and coherence of particle-like ink droplets.",
        "num_frames": 17
    },
    {
        "id": "prompt_11_calligraphy_stroke",
        "english": "A stroke of running-cursive style calligraphy, with continuous momentum and a natural finish, emphasizing the continuity of the brush tip's path, 8 frames.",
        "num_frames": 17
    }
]

# --- éšæœºç§å­åˆ—è¡¨ ---
RANDOM_SEEDS = [42, 100, 400]

# --- è·¯å¾„é…ç½® ---
OUTPUT_DIR = Path("./evaluation_videos_suite")
ORIGINAL_LORA_PATH = Path("/share/project/chengweiwu/code/Chinese_ink/hanzhe/ink_wash/lora_outputs/inkwash_style_v1/epoch-18.safetensors")
FINETUNED_DIT_PATH = Path("/share/project/chengweiwu/code/Chinese_ink/hanzhe/code/DiffSynth-Studio/runs/staged_training_final_oom_fix/checkpoints/dit_finetuned_step_final.pth")
TEMPORAL_MODULE_PATH = Path("/share/project/chengweiwu/code/Chinese_ink/hanzhe/code/DiffSynth-Studio/runs/staged_training_final_oom_fix/checkpoints/temporal_module_step_final.pth")
FLOW_PREDICTOR_PATH = Path("/share/project/chengweiwu/code/Chinese_ink/hanzhe/code/DiffSynth-Studio/runs/staged_training_final_oom_fix/checkpoints/flow_predictor_step_final.pth")
BASE_MODEL_ID = "Wan-AI/Wan2.1-T2V-1.3B"

# --- æ¨¡å‹ä¸æ¨ç†å‚æ•° ---
device = torch.device("cuda")
dtype = torch.float16
height, width = 512, 512
fps = 8
num_inference_steps = 50
cfg_scale = 7.0

# ============================================================================
# 3. åˆå§‹åŒ–æ¨¡å‹ä¸ç¯å¢ƒ (å‡½æ•°å·²ä¿®æ­£)
# ============================================================================

def initialize_pipeline():
    """
    åŠ è½½åŸºç¡€æ¨¡å‹å¹¶è¿”å›pipelineå®ä¾‹å’ŒåŸå§‹DiTæƒé‡ã€‚(å·²ä¿®æ­£)
    
    ä¿®å¤è¯´æ˜ï¼š
    ç›´æ¥é€šè¿‡ `WanVideoPipeline.from_pretrained` åŠ è½½åŸºç¡€æ¨¡å‹ï¼Œå¹¶
    ä½¿ç”¨ `ModelConfig` æ˜¾å¼æŒ‡å®šæ‰€éœ€çš„æƒé‡æ–‡ä»¶ï¼Œç¡®ä¿åœ¨æœ¬åœ°ç¼“å­˜
    å·²å­˜åœ¨çš„æƒ…å†µä¸‹èƒ½å¤Ÿç¨³å®šå¤ç°è®­ç»ƒè„šæœ¬çš„åˆå§‹åŒ–æµç¨‹ã€‚
    """
    print("--- æ­£åœ¨åŠ è½½åŸºç¡€ WanVideoPipeline (from_pretrained) ---")

    model_configs = [
        ModelConfig(model_id=BASE_MODEL_ID, origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth"),
        ModelConfig(model_id=BASE_MODEL_ID, origin_file_pattern="diffusion_pytorch_model.safetensors"),
        ModelConfig(model_id=BASE_MODEL_ID, origin_file_pattern="Wan2.1_VAE.pth"),
    ]

    pipe = WanVideoPipeline.from_pretrained(
        device=device,
        torch_dtype=dtype,
        model_configs=model_configs,
    )
    
    # ä¿å­˜ä¸€ä»½å¹²å‡€çš„åŸå§‹DiTæƒé‡ï¼Œç”¨äºåœ¨å„çº§åˆ«é—´é‡ç½®çŠ¶æ€
    original_dit_state_dict = {k: v.clone().cpu() for k, v in pipe.dit.state_dict().items()}
    print("--- åŸºç¡€æ¨¡å‹åŠ è½½å®Œæ¯•ï¼ŒåŸå§‹DiTçŠ¶æ€å·²ä¿å­˜ ---")
    return pipe, original_dit_state_dict

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    
    # --- åˆ›å»ºè¾“å‡ºç›®å½• ---
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    print(f"è§†é¢‘å°†ä¿å­˜è‡³: {OUTPUT_DIR.resolve()}")
    
    # --- åˆå§‹åŒ–æ¨¡å‹ ---
    pipe, original_dit_state_dict = initialize_pipeline()

    # åŠ è½½ä¸€æ¬¡å¾®è°ƒåçš„DiTæƒé‡ï¼Œä»¥å¤‡åç”¨
    if FINETUNED_DIT_PATH.exists():
        print(f"--- é¢„åŠ è½½å¾®è°ƒDiTæƒé‡æ¥æº: {FINETUNED_DIT_PATH.name} ---")
        finetuned_dit_state_dict = torch.load(FINETUNED_DIT_PATH, map_location="cpu")
    else:
        print(f"è­¦å‘Š: æœªæ‰¾åˆ°å¾®è°ƒDiTæƒé‡æ–‡ä»¶: {FINETUNED_DIT_PATH}")
        finetuned_dit_state_dict = None

    # --- è®¡ç®—ä»»åŠ¡æ€»é‡å¹¶åˆå§‹åŒ–è¿›åº¦æ¡ ---
    total_videos = len(EVALUATION_PROMPTS) * len(RANDOM_SEEDS) * 4
    pbar = tqdm(total=total_videos, desc="å…¨å±€ç”Ÿæˆè¿›åº¦", unit="video")

    # --- å¼€å§‹æ‰¹é‡ç”Ÿæˆå¾ªç¯ ---
    for prompt_config in EVALUATION_PROMPTS:
        for seed in RANDOM_SEEDS:
            
            prompt_id = prompt_config["id"]
            prompt_text = prompt_config["english"]
            num_frames = prompt_config["num_frames"]
            
            # --- Level 0: Absolute Baseline ---
            level_id = 0
            video_path = OUTPUT_DIR / f"{prompt_id}_level{level_id}_seed{seed}.mp4"
            pbar.set_description(f"Processing Level {level_id} (Seed {seed}, {prompt_id})")
            try:
                # çŠ¶æ€é‡ç½®: æ¢å¤åŸå§‹DiTï¼Œç§»é™¤æ—¶åºæ¨¡å—
                pipe.dit.load_state_dict({k: v.to(device) for k, v in original_dit_state_dict.items()})
                pipe.temporal_module = None
                pipe.flow_predictor = None
                
                # ç”Ÿæˆè§†é¢‘
                video_frames = pipe(prompt_text, seed=seed, num_frames=num_frames, height=height, width=width, num_inference_steps=num_inference_steps, cfg_scale=cfg_scale)
                save_video(video_frames, str(video_path), fps=fps)
                # print(f"âœ… Level {level_id} è§†é¢‘å·²ä¿å­˜: {video_path.name}")
            except Exception as e:
                print(f"\nâŒ Level {level_id} ({prompt_id}, seed {seed}) ç”Ÿæˆå¤±è´¥: {e}")
                traceback.print_exc()
            pbar.update(1)

            # --- Level 1: Style Baseline (LoRA) ---
            level_id = 1
            video_path = OUTPUT_DIR / f"{prompt_id}_level{level_id}_seed{seed}.mp4"
            pbar.set_description(f"Processing Level {level_id} (Seed {seed}, {prompt_id})")
            try:
                # çŠ¶æ€é‡ç½®: æ¢å¤åŸå§‹DiTï¼Œç„¶ååŠ è½½LoRA
                pipe.dit.load_state_dict({k: v.to(device) for k, v in original_dit_state_dict.items()})
                pipe.load_lora(pipe.dit, str(ORIGINAL_LORA_PATH), alpha=1.0)
                pipe.temporal_module = None
                pipe.flow_predictor = None

                # ç”Ÿæˆè§†é¢‘
                video_frames = pipe(prompt_text, seed=seed, num_frames=num_frames, height=height, width=width, num_inference_steps=num_inference_steps, cfg_scale=cfg_scale)
                save_video(video_frames, str(video_path), fps=fps)
                # print(f"âœ… Level {level_id} è§†é¢‘å·²ä¿å­˜: {video_path.name}")
            except Exception as e:
                print(f"\nâŒ Level {level_id} ({prompt_id}, seed {seed}) ç”Ÿæˆå¤±è´¥: {e}")
                traceback.print_exc()
            pbar.update(1)
            
            # --- Level 2: Jointly Trained Style (Fine-tuned DiT) ---
            level_id = 2
            video_path = OUTPUT_DIR / f"{prompt_id}_level{level_id}_seed{seed}.mp4"
            pbar.set_description(f"Processing Level {level_id} (Seed {seed}, {prompt_id})")
            if finetuned_dit_state_dict:
                try:
                    # çŠ¶æ€é‡ç½®: æ¢å¤åŸºç¡€DiTï¼Œå†åŠ è½½å¾®è°ƒåçš„æƒé‡ï¼Œç§»é™¤æ—¶åºæ¨¡å—
                    pipe.dit.load_state_dict({k: v.to(device) for k, v in original_dit_state_dict.items()})
                    pipe.dit.load_state_dict({k: v.to(device) for k, v in finetuned_dit_state_dict.items()}, strict=False)
                    pipe.temporal_module = None
                    pipe.flow_predictor = None

                    # ç”Ÿæˆè§†é¢‘
                    video_frames = pipe(prompt_text, seed=seed, num_frames=num_frames, height=height, width=width, num_inference_steps=num_inference_steps, cfg_scale=cfg_scale)
                    save_video(video_frames, str(video_path), fps=fps)
                    # print(f"âœ… Level {level_id} è§†é¢‘å·²ä¿å­˜: {video_path.name}")
                except Exception as e:
                    print(f"\nâŒ Level {level_id} ({prompt_id}, seed {seed}) ç”Ÿæˆå¤±è´¥: {e}")
                    traceback.print_exc()
            else:
                print(f"\nâ­ï¸  è·³è¿‡ Level {level_id} ({prompt_id}, seed {seed})ï¼Œå› ä¸ºç¼ºå°‘å¾®è°ƒDiTæƒé‡ã€‚")
            pbar.update(1)

            # --- Level 3: Fully Enhanced Model ---
            level_id = 3
            video_path = OUTPUT_DIR / f"{prompt_id}_level{level_id}_seed{seed}.mp4"
            pbar.set_description(f"Processing Level {level_id} (Seed {seed}, {prompt_id})")
            if finetuned_dit_state_dict and TEMPORAL_MODULE_PATH.exists() and FLOW_PREDICTOR_PATH.exists():
                try:
                    # çŠ¶æ€è®¾ç½®: å…ˆæ¢å¤åŸºç¡€DiTï¼Œå†åŠ è½½å¾®è°ƒç‰ˆæœ¬ï¼Œç„¶ååŠ è½½æ—¶åºæ¨¡å—
                    pipe.dit.load_state_dict({k: v.to(device) for k, v in original_dit_state_dict.items()})
                    pipe.dit.load_state_dict({k: v.to(device) for k, v in finetuned_dit_state_dict.items()}, strict=False)
                    
                    # åŠ è½½å¹¶æŒ‚è½½Temporal Module
                    temporal_module = TemporalModule(latent_channels=16, style_dim=None).to(device, dtype=dtype).eval()
                    temporal_module.load_state_dict(torch.load(TEMPORAL_MODULE_PATH, map_location=device))
                    pipe.temporal_module = temporal_module

                    # åŠ è½½å¹¶æŒ‚è½½Flow Predictor
                    flow_predictor = LatentFlowPredictor(in_channels=16).to(device, dtype=dtype).eval()
                    flow_predictor.load_state_dict(torch.load(FLOW_PREDICTOR_PATH, map_location=device))
                    pipe.flow_predictor = flow_predictor

                    # ç”Ÿæˆè§†é¢‘
                    video_frames = pipe(prompt_text, seed=seed, num_frames=num_frames, height=height, width=width, num_inference_steps=num_inference_steps, cfg_scale=cfg_scale)
                    save_video(video_frames, str(video_path), fps=fps)
                    # print(f"âœ… Level {level_id} è§†é¢‘å·²ä¿å­˜: {video_path.name}")
                except Exception as e:
                    print(f"\nâŒ Level {level_id} ({prompt_id}, seed {seed}) ç”Ÿæˆå¤±è´¥: {e}")
                    traceback.print_exc()
            else:
                 print(f"\nâ­ï¸  è·³è¿‡ Level {level_id} ({prompt_id}, seed {seed})ï¼Œå› ä¸ºç¼ºå°‘å¿…è¦çš„æ¨¡å‹æƒé‡ã€‚")
            pbar.update(1)

    pbar.close()
    print("\nğŸ‰ æ‰€æœ‰è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²å®Œæˆ! ğŸ‰")

if __name__ == "__main__":
    main()
